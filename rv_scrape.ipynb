{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2211e804-777f-486e-a30e-58bacf309ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def setup_driver():\n",
    "   options = uc.ChromeOptions()\n",
    "   options.headless = False\n",
    "   options.add_argument('--start-maximized')\n",
    "   return uc.Chrome(options=options)\n",
    "\n",
    "def get_single_page(page_number):\n",
    "   print(f\"\\n=== Starting collection for page {page_number} at {datetime.datetime.now().strftime('%I:%M %p')} ===\")\n",
    "   \n",
    "   driver = setup_driver()\n",
    "   try:\n",
    "       url = f'https://www.rvtrader.com/New-Winnebago/rvs-for-sale?make=Winnebago%7C2307464&condition=N&seller_type=dealer&zip=33021&radius=10000&page={page_number}'\n",
    "       \n",
    "       print(f\"\\nNavigating to page {page_number}...\")\n",
    "       driver.get(url)\n",
    "       \n",
    "       # Wait for page to load\n",
    "       print(\"Waiting 10 seconds for page to load...\")\n",
    "       time.sleep(10)\n",
    "       \n",
    "       # Save the source\n",
    "       filename = f'rv_page_{page_number}_source.html'\n",
    "       with open(filename, 'w', encoding='utf-8') as f:\n",
    "           f.write(driver.page_source)\n",
    "       \n",
    "       size = os.path.getsize(filename)\n",
    "       print(f\"Saved file: {filename} ({size/1024:.2f} KB)\")\n",
    "       \n",
    "   finally:\n",
    "       driver.quit()\n",
    "       print(f\"Browser closed for page {page_number}\")\n",
    "\n",
    "def main():\n",
    "   start_page = int(input(\"Start from page number: \"))\n",
    "   end_page = int(input(\"End at page number: \"))\n",
    "   wait_minutes = int(input(\"Minutes to wait between pages: \"))\n",
    "   \n",
    "   for page in range(start_page, end_page + 1):\n",
    "       get_single_page(page)\n",
    "       \n",
    "       if page < end_page:\n",
    "           wait_time = wait_minutes * 60\n",
    "           print(f\"\\nWaiting {wait_minutes} minutes before next page...\")\n",
    "           print(f\"Next page will start at: {(datetime.datetime.now() + datetime.timedelta(minutes=wait_minutes)).strftime('%I:%M %p')}\")\n",
    "           time.sleep(wait_time)\n",
    "           \n",
    "   print(\"\\n=== Collection Complete! ===\")\n",
    "   print(f\"Collected pages {start_page} through {end_page}\")\n",
    "   \n",
    "   # Show summary of files\n",
    "   print(\"\\nFiles collected:\")\n",
    "   for page in range(start_page, end_page + 1):\n",
    "       filename = f'rv_page_{page}_source.html'\n",
    "       if os.path.exists(filename):\n",
    "           size = os.path.getsize(filename)\n",
    "           print(f\"Page {page}: {size/1024:.2f} KB\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   print(\"=== RV Trader Multi-Page Collector ===\")\n",
    "   print(\"This will automatically collect pages with waits between them\")\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed659f6-7e5f-4f96-978b-e7ee0a258a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_json_from_html(file_path):\n",
    "    # Read the HTML file\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Find the JSON data within script tags\n",
    "    json_match = re.search(r'<script type=\"application/ld\\+json\">(.*?)</script>', content, re.DOTALL)\n",
    "    if json_match:\n",
    "        json_str = json_match.group(1)\n",
    "        # Remove escaped forward slashes\n",
    "        json_str = json_str.replace('\\/', '/')\n",
    "        return json.loads(json_str)\n",
    "    return None\n",
    "\n",
    "def parse_rv_data(json_data):\n",
    "    # Navigate to the offers array\n",
    "    if not json_data or 'offers' not in json_data:\n",
    "        return []\n",
    "        \n",
    "    offers = json_data['offers']['offers']\n",
    "    \n",
    "    rv_list = []\n",
    "    for offer in offers:\n",
    "        item = offer['itemOffered']\n",
    "        \n",
    "        # Extract model parts from the name\n",
    "        name_parts = item['name'].split()\n",
    "        \n",
    "        rv_info = {\n",
    "            'year': name_parts[0],\n",
    "            'model': ' '.join(name_parts[2:]),  # Everything after \"Winnebago\"\n",
    "            'price': float(item['price']),\n",
    "            'condition': item['itemCondition'],\n",
    "            'url': offer['url']\n",
    "        }\n",
    "        rv_list.append(rv_info)\n",
    "    \n",
    "    return rv_list\n",
    "\n",
    "def main():\n",
    "    # Find all RV page files\n",
    "    html_files = [f for f in os.listdir() if f.startswith('rv_page_') and f.endswith('.html')]\n",
    "    \n",
    "    print(f\"Found {len(html_files)} HTML files\")\n",
    "    \n",
    "    all_rv_data = []\n",
    "    \n",
    "    # Process each file\n",
    "    for file in sorted(html_files):\n",
    "        print(f\"\\nProcessing {file}...\")\n",
    "        \n",
    "        # Check file size\n",
    "        size = os.path.getsize(file)\n",
    "        print(f\"File size: {size/1024:.2f} KB\")\n",
    "        \n",
    "        if size < 10000:  # Skip small files (likely error pages)\n",
    "            print(\"File too small, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        # Extract and parse data\n",
    "        json_data = extract_json_from_html(file)\n",
    "        if json_data:\n",
    "            rv_data = parse_rv_data(json_data)\n",
    "            all_rv_data.extend(rv_data)\n",
    "            print(f\"Added {len(rv_data)} RVs from this file\")\n",
    "        else:\n",
    "            print(\"No valid JSON data found in file\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(all_rv_data)\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_filename = 'all_winnebago_rvs.csv'\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    \n",
    "    print(f\"\\nTotal RVs collected: {len(df)}\")\n",
    "    print(f\"Data saved to: {csv_filename}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Show some basic statistics\n",
    "    print(\"\\nPrice Statistics:\")\n",
    "    print(df['price'].describe())\n",
    "    \n",
    "    # Count by year\n",
    "    print(\"\\nRVs by Year:\")\n",
    "    print(df['year'].value_counts().sort_index())\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== RV Data Combiner ===\")\n",
    "    df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e2a6d08-fe8d-40aa-b138-addb7e36310f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/avijames'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b20af8-a70d-4f93-b815-aa766734ce7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
